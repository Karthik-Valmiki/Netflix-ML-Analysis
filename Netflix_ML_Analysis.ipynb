{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b2a895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<DATA SET IMPORTED SUCCESSFULLY>>>>>>>>>>>>>>>>>>>\n",
      "CLASSIFICATION MODELS RESULT:\n",
      "\n",
      ".........Logistic Regression........\n",
      "Accuracy: 0.7486301369863013\n",
      "Confusion matrix: [[1029   38]\n",
      " [ 329   64]]\n",
      "Classification reports:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85      1067\n",
      "           1       0.63      0.16      0.26       393\n",
      "\n",
      "    accuracy                           0.75      1460\n",
      "   macro avg       0.69      0.56      0.55      1460\n",
      "weighted avg       0.72      0.75      0.69      1460\n",
      "\n",
      ".........Decision Tree........\n",
      "Accuracy: 0.9924657534246575\n",
      "Confusion matrix: [[1058    9]\n",
      " [   2  391]]\n",
      "Classification reports:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1067\n",
      "           1       0.98      0.99      0.99       393\n",
      "\n",
      "    accuracy                           0.99      1460\n",
      "   macro avg       0.99      0.99      0.99      1460\n",
      "weighted avg       0.99      0.99      0.99      1460\n",
      "\n",
      ".........Random Forest........\n",
      "Accuracy: 0.9917808219178083\n",
      "Confusion matrix: [[1057   10]\n",
      " [   2  391]]\n",
      "Classification reports:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1067\n",
      "           1       0.98      0.99      0.98       393\n",
      "\n",
      "    accuracy                           0.99      1460\n",
      "   macro avg       0.99      0.99      0.99      1460\n",
      "weighted avg       0.99      0.99      0.99      1460\n",
      "\n",
      ".........KNN........\n",
      "Accuracy: 0.9493150684931507\n",
      "Confusion matrix: [[1013   54]\n",
      " [  20  373]]\n",
      "Classification reports:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1067\n",
      "           1       0.87      0.95      0.91       393\n",
      "\n",
      "    accuracy                           0.95      1460\n",
      "   macro avg       0.93      0.95      0.94      1460\n",
      "weighted avg       0.95      0.95      0.95      1460\n",
      "\n",
      ".........SVM........\n",
      "Accuracy: 0.8726027397260274\n",
      "Confusion matrix: [[993  74]\n",
      " [112 281]]\n",
      "Classification reports:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      1067\n",
      "           1       0.79      0.72      0.75       393\n",
      "\n",
      "    accuracy                           0.87      1460\n",
      "   macro avg       0.85      0.82      0.83      1460\n",
      "weighted avg       0.87      0.87      0.87      1460\n",
      "\n",
      ".......REGRESSION RESULTS ........\n",
      "........Linear Regression..........\n",
      "MAE: 5.192711639857977\n",
      "RMSE: 8.334082379942219\n",
      "R2 Score: 0.07507579216489191\n",
      "........Decision Tree..........\n",
      "MAE: 5.4057762193488035\n",
      "RMSE: 9.622525460638975\n",
      "R2 Score: -0.23301598255723732\n",
      "........Random Forest..........\n",
      "MAE: 5.045709518222653\n",
      "RMSE: 8.657740851200137\n",
      "R2 Score: 0.001840987398664451\n",
      "........SVM..........\n",
      "MAE: 4.424127345176254\n",
      "RMSE: 8.320126820566031\n",
      "R2 Score: 0.07817080057041237\n",
      "........KNN..........\n",
      "MAE: 5.064246575342469\n",
      "RMSE: 8.354516455515514\n",
      "R2 Score: 0.07053464643979102\n",
      "<<<<<<<<<<<<<<<<<<<< SUCCESSFULLY FINISHED >>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "#............................................................\n",
    "#                     STEP - 1 \n",
    "#............................................................\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix , accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score \n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier , DecisionTreeRegressor \n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor \n",
    "from sklearn.svm import SVC , SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier , KNeighborsRegressor\n",
    "\n",
    "\n",
    "#preprocessing -- to clean , transform and to prepare data before feeding it into machine learning model \n",
    "#Convert text to numbers - (LabelEncoder)\n",
    "#Scale values to similar ranges - (StandardScaler)\n",
    "\n",
    "#metrics  -- tools to evaluate the performance of the ml model \n",
    "#For classification: Accuracy, precision, confusion matrix\n",
    "#For regression: MAE, RMSE, RÂ²\n",
    "\n",
    "#linear_model -- model based on linear relationship between input and output \n",
    "# this predicts the output with straight line relationship \n",
    "\n",
    "# tree --  model that splits the data using decisoin types or flowchart \n",
    "# it works well without scaling or preprocessing \\\n",
    "\n",
    "#ensemble -- model which combines multiple weak ones and create an strong one with this \n",
    "\n",
    "\n",
    "#SVM --  a strong model which draws the optimal boundary between classes \n",
    "#finds the best dimeensional even in high dimensional or non-linear spaces \n",
    "#best for small and medium datsets \n",
    "\n",
    "\n",
    "#neighbors - based on the closenes of the data points it came\n",
    "#best for simple probleming and refernce models \n",
    "\n",
    "\n",
    "\n",
    "#............................................................\n",
    "#                     STEP - 2\n",
    "#............................................................\n",
    "\n",
    "file_path = os.path.join('Netflix_data','netflix_titles.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"<<<<<<<<<<<<<<<<<<DATA SET IMPORTED SUCCESSFULLY>>>>>>>>>>>>>>>>>>>\")\n",
    "\n",
    "\n",
    "\n",
    "#............................................................\n",
    "#                     STEP - 3 (clean and preprocess)\n",
    "#............................................................\n",
    "\n",
    "\n",
    "df = df.dropna(subset= ['cast','country','duration','rating'])\n",
    "\n",
    "def parse_duration(value):   #parse_duration - converts duration string into numericalvalue(in min)\n",
    "    if 'Season' in value:\n",
    "        return int(value.split()[0]) * 60\n",
    "    else:\n",
    "        return int(value.split()[0])\n",
    "    \n",
    "df['duration_mins'] = df['duration'].apply(parse_duration)\n",
    "    \n",
    "#LabelEncoders  ---  which converts text into numbers \n",
    "label_encoder = {}\n",
    "for col in ['type','rating','country']:\n",
    "    le = LabelEncoder()                          #df[col] = df['type'] df['rating'] etcc\n",
    "    df[col] = le.fit_transform(df[col])    #.fit = learns all unique text labels in that column\n",
    "                                           #.transform - converts those text labels into numbers\n",
    "    label_encoder[col] = le\n",
    "\n",
    "\n",
    "\n",
    "#............................................................\n",
    "#                     STEP - 4 (features and targets)\n",
    "#............................................................\n",
    "features = df[['rating','country','duration_mins']]      #in ML feature(X) - input we given\n",
    "                                                        #target(Y) - what we need the model to predict\n",
    "target_class = df['type']\n",
    "target_reg = df['release_year']\n",
    "\n",
    "#scale\n",
    "scaler = StandardScaler()\n",
    "features_scale = scaler.fit_transform(features)\n",
    "\n",
    "#train/test/Split\n",
    "x_train_cls,x_test_cls,y_train_cls,y_test_cls = train_test_split(features_scale,target_class,test_size=0.2,random_state=46)\n",
    "x_train_reg,x_test_reg,y_train_reg,y_test_reg= train_test_split(features_scale,target_reg,test_size=0.2,random_state=46)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#................................................................................\n",
    "#                     STEP - 5 (Model Training and evaluation)\n",
    "#................................................................................\n",
    "#classification models \n",
    "classification_models = {\n",
    "     \"Logistic Regression\": LogisticRegression(),\n",
    "     \"Decision Tree\" : DecisionTreeClassifier(),\n",
    "     \"Random Forest\" : RandomForestClassifier(),\n",
    "     \"KNN\" : KNeighborsClassifier(),\n",
    "     \"SVM\":SVC()\n",
    "}\n",
    "\n",
    "print(\"CLASSIFICATION MODELS RESULT:\\n\")\n",
    "for name,model in classification_models.items():\n",
    "    model.fit(x_train_cls,y_train_cls)\n",
    "    preds = model.predict(x_test_cls)\n",
    "    print(f\".........{name}........\")\n",
    "    print(\"Accuracy:\",accuracy_score(y_test_cls,preds))    #how many predicitons were correcr\n",
    "    print(\"Confusion matrix:\",confusion_matrix(y_test_cls,preds))  #breakdown of correct/incorrect predicitons \n",
    "    print(\"Classification reports:\",classification_report(y_test_cls,preds)) #includes precision,recall F1-Score\n",
    "\n",
    "\n",
    "#Regression models \n",
    "regression_models = {\n",
    "    \"Linear Regression\" : LinearRegression(),\n",
    "    \"Decision Tree\" : DecisionTreeRegressor(),\n",
    "    \"Random Forest\" : RandomForestRegressor(),\n",
    "    \"SVM\" : SVR(),\n",
    "    \"KNN\":KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "print(\".......REGRESSION RESULTS ........\")\n",
    "for name,model in regression_models.items():\n",
    "    model.fit(x_train_reg,y_train_reg)\n",
    "    preds = model.predict(x_test_reg)\n",
    "    print(f\"........{name}..........\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_test_reg, preds))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_reg, preds)))\n",
    "    print(\"R2 Score:\", r2_score(y_test_reg,preds))\n",
    "\n",
    "\n",
    "\n",
    "print(\"<<<<<<<<<<<<<<<<<<<< SUCCESSFULLY FINISHED >>>>>>>>>>>>>>>>>>>>>>>>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
